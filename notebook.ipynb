{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gVXupOn7SnTY"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "cfb7b8e6-3690-4cc5-8afc-d261d026ba2a"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import librosa\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import svm, metrics\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-uVCr7NLS7X9"
   },
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "1cae3052-e953-40e6-bd78-1e69e306ae15"
   },
   "outputs": [],
   "source": [
    "TRAIN_BASE_DIRECTORY = \"/home/devin/Documents/datasets/nsynth-train/audio\"\n",
    "VALID_BASE_DIRECTORY = \"/home/devin/Documents/datasets/nsynth-valid/audio\"\n",
    "TEST_BASE_DIRECTORY = \"/home/devin/Documents/datasets/nsynth-test/audio\"\n",
    "NUM_MFCC_FEATURES = 40\n",
    "\n",
    "LOAD_PICKLE = False\n",
    "X_PICKLE = \"/home/devin/Documents/datasets/nsynth-train/X_train.pickle\"\n",
    "Y_PICKLE = \"/home/devin/Documents/datasets/nsynth-train/y_train.pickle\"\n",
    "\n",
    "TRAIN_TEST_SPLIT = 0.10\n",
    "\n",
    "STR_INT_MAP = [\n",
    "  \"bass\",\n",
    "  \"brass\",\n",
    "  \"flute\",\n",
    "  \"guitar\",\n",
    "  \"keyboard\",\n",
    "  \"mallet\",\n",
    "  \"organ\",\n",
    "  \"reed\",\n",
    "  \"string\",\n",
    "  \"\",\n",
    "  \"vocal\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X0n3Dmp0TBQc"
   },
   "source": [
    "# Helper Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "6bfa57a9-14a9-4eb4-91b4-785c1178a62b"
   },
   "outputs": [],
   "source": [
    "def grab_label(file: str) -> str:\n",
    "    '''\n",
    "    Grabs the label (the instrument) from the filename of the WAV audio file.\n",
    "\n",
    "    The file names are something like:\n",
    "      /path/to/audio/bass_some_other_words.wav\n",
    "\n",
    "    The first '/' split grabs 'bass_some_other_words.wav'.\n",
    "    The second '.' split grabs 'bass_some_other_words'.\n",
    "    The third '_' split grabs 'bass'.\n",
    "\n",
    "    All of the nsynth audio files are in the same format. If we wanted to get\n",
    "    fancy, nsynth also has a JSON file explaining each file and what class\n",
    "    it is from, so I could write a JSON parser instead.\n",
    "    '''\n",
    "    return file.split(\"/\")[-1].split(\".\")[0].split(\"_\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "45471e9a-501c-4af3-968c-bb7601a10483"
   },
   "outputs": [],
   "source": [
    "def grab_features(file: str, num_features: int) -> str:\n",
    "  '''\n",
    "  Grabs `num_features` MFCC features from a WAV file.\n",
    "\n",
    "  The WAV file is loaded in at 16kHz at 4 seconds using librosa.load. Then,\n",
    "  MFCC features are calculated using librosa.feature.mfcc. For nsynth audio\n",
    "  files, this loads a matrix of (num_features, 126). 126 is the time.\n",
    "\n",
    "  For when num_features = 40 it loads a 2D array of (40, 126). We then flatten\n",
    "  this array to 1D, which gives us a feature vector of 40 * 126 = 5040.\n",
    "  '''\n",
    "  sig, sr = librosa.load(\n",
    "    path=file,\n",
    "    sr=16_000,\n",
    "    duration=float(4)\n",
    "  )\n",
    "\n",
    "  features = librosa.feature.mfcc(\n",
    "    y=sig,\n",
    "    sr=sr,\n",
    "    n_mfcc=num_features\n",
    "  )\n",
    "\n",
    "  return np.asarray(features).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "827a8b36-b157-4448-9662-e97d831427f5"
   },
   "outputs": [],
   "source": [
    "def load(directory: str, num_features: int):\n",
    "    '''\n",
    "    Loads an entire directory of WAV of audio files.\n",
    "\n",
    "    We load all of the files in the directory. We assume that these files are\n",
    "    all in the same format and all WAV files (which for our case is fine, since\n",
    "    they are).\n",
    "\n",
    "    I then give them a shuffle. This was mainly used for testing, when only\n",
    "    loading 100 or so files. The files are in order, so the first 100 are\n",
    "    all of the same class. Shuffling the file list fixes this issue.\n",
    "\n",
    "    Then, we collect that 5040 feature vector and the label for each audio file,\n",
    "    and appened it to our lists.\n",
    "    '''\n",
    "    start = time.time()\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    # Check if the directory passed in is actually a directory\n",
    "    if os.path.isdir(directory) is False:\n",
    "        return [], [], 0, \"'%s' is not a directory\" % directory\n",
    "    \n",
    "    # Get a list of files in the directory. They should be full paths.\n",
    "    files = np.asarray([os.path.join(directory, name) for name in os.listdir(\"%s\" % directory)])\n",
    "    np.random.shuffle(files)\n",
    "    \n",
    "    # Grab the features and label for each audio file.\n",
    "    for file in files:\n",
    "        features = grab_features(file=file, num_features=num_features)\n",
    "        label = grab_label(file=file)\n",
    "        \n",
    "        X.append(features)\n",
    "        y.append(label)\n",
    "        \n",
    "    elapsed = time.time() - start\n",
    "    return np.asarray(X), np.asarray(y), elapsed, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-QVd9m8ZVkZr"
   },
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7dc91e82-bbcb-46d1-b36a-97d43098779e",
    "outputId": "5c553b50-c7c9-466c-f197-f8a759bdc1c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickled X.\n",
      "Pickled y.\n",
      "Loaded 289205 files in 2751.667837 seconds.\n"
     ]
    }
   ],
   "source": [
    "# Training set took around 45 minutes\n",
    "\n",
    "X = np.asarray([])\n",
    "y = np.asarray([])\n",
    "elapsed = float(0)\n",
    "error_msg = None\n",
    "\n",
    "if LOAD_PICKLE:\n",
    "  start_time = time.time()\n",
    "  with open(X_PICKLE, 'rb') as f:\n",
    "    X = pickle.load(f)\n",
    "  with open(Y_PICKLE, 'rb') as f:\n",
    "    y = pickle.load(f)\n",
    "\n",
    "  elapsed = time.time() - start_time\n",
    "else:\n",
    "  X, y, elapsed, error_msg = load(directory=TRAIN_BASE_DIRECTORY, num_features=NUM_MFCC_FEATURES)\n",
    "  with open(X_PICKLE, 'wb') as f:\n",
    "    pickle.dump(X, f)\n",
    "    print(\"Pickled X.\")\n",
    "\n",
    "  with open(Y_PICKLE, 'wb') as f:\n",
    "    pickle.dump(y, f)\n",
    "    print(\"Pickled y.\")\n",
    "\n",
    "if error_msg is None:\n",
    "    print(\"Loaded %d files in %f seconds.\" % (len(X), elapsed))\n",
    "else:\n",
    "    print(\"%s\" % (error_msg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "PPZVYkkUls83"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TRAIN_TEST_SPLIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "09fa603f-ca25-4201-9c05-300fbbbc5834",
    "outputId": "26638ee5-d42e-4330-fd4d-0e8fbdc47813"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (260284, 5040)\n",
      "y_train: (260284,)\n",
      "X_test: (28921, 5040)\n",
      "y_test: (28921,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train:\", X_train.shape)\n",
    "print(\"y_train:\", y_train.shape)\n",
    "\n",
    "print(\"X_test:\", X_test.shape)\n",
    "print(\"y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "re-gSFehVpFf"
   },
   "source": [
    "# Run some classifiers from SKLearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "9h0u4N-ft8OQ"
   },
   "outputs": [],
   "source": [
    "classifiers = [\n",
    "  DecisionTreeClassifier(),\n",
    "  MLPClassifier(alpha=1, max_iter=1000),\n",
    "  RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "  AdaBoostClassifier(),\n",
    "  KNeighborsClassifier()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uegySAB0uF9y"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        bass       0.92      0.91      0.92      6669\n",
      "       brass       0.92      0.93      0.92      1266\n",
      "       flute       0.90      0.90      0.90       927\n",
      "      guitar       0.86      0.85      0.85      3310\n",
      "    keyboard       0.88      0.89      0.89      4984\n",
      "      mallet       0.88      0.87      0.87      3347\n",
      "       organ       0.95      0.95      0.95      3432\n",
      "        reed       0.91      0.93      0.92      1458\n",
      "      string       0.94      0.96      0.95      1918\n",
      "       synth       0.87      0.86      0.87       554\n",
      "       vocal       0.92      0.95      0.93      1056\n",
      "\n",
      "    accuracy                           0.90     28921\n",
      "   macro avg       0.90      0.91      0.91     28921\n",
      "weighted avg       0.90      0.90      0.90     28921\n",
      " \n",
      "\n",
      "\n",
      "MLPClassifier(alpha=1, max_iter=1000)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        bass       0.56      0.73      0.63      6669\n",
      "       brass       0.78      0.67      0.72      1266\n",
      "       flute       0.34      0.25      0.29       927\n",
      "      guitar       0.75      0.33      0.46      3310\n",
      "    keyboard       0.61      0.41      0.49      4984\n",
      "      mallet       0.42      0.70      0.53      3347\n",
      "       organ       0.82      0.81      0.81      3432\n",
      "        reed       0.37      0.64      0.47      1458\n",
      "      string       0.92      0.56      0.70      1918\n",
      "       synth       0.57      0.08      0.14       554\n",
      "       vocal       0.68      0.56      0.61      1056\n",
      "\n",
      "    accuracy                           0.58     28921\n",
      "   macro avg       0.62      0.52      0.53     28921\n",
      "weighted avg       0.63      0.58      0.58     28921\n",
      " \n",
      "\n",
      "\n",
      "RandomForestClassifier(max_depth=5, max_features=1, n_estimators=10)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        bass       0.28      0.90      0.43      6669\n",
      "       brass       0.00      0.00      0.00      1266\n",
      "       flute       0.00      0.00      0.00       927\n",
      "      guitar       0.00      0.00      0.00      3310\n",
      "    keyboard       0.31      0.19      0.23      4984\n",
      "      mallet       0.50      0.11      0.17      3347\n",
      "       organ       0.58      0.60      0.59      3432\n",
      "        reed       0.73      0.13      0.22      1458\n",
      "      string       0.59      0.08      0.15      1918\n",
      "       synth       0.00      0.00      0.00       554\n",
      "       vocal       1.00      0.00      0.00      1056\n",
      "\n",
      "    accuracy                           0.34     28921\n",
      "   macro avg       0.36      0.18      0.16     28921\n",
      "weighted avg       0.36      0.34      0.25     28921\n",
      " \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for clf in classifiers:\n",
    "  clf.fit(X_train, y_train)\n",
    "\n",
    "  pred = clf.predict(X_test)\n",
    "  report = metrics.classification_report(\n",
    "    y_true=y_test,\n",
    "    y_pred=pred,\n",
    "    zero_division=0\n",
    "  )\n",
    "\n",
    "  print(clf)\n",
    "  print(report, \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "3Mkl2OOIoXnq",
    "outputId": "743e6bcf-49a2-47e3-8765-eb7599f29e2d"
   },
   "outputs": [],
   "source": [
    "# X_test, y_test\n",
    "dt = classifiers[1]\n",
    "dt.fit(X_train, y_train)\n",
    "predictions = dt.predict(X_test)\n",
    "\n",
    "print(X_test.shape)\n",
    "\"\"\"X_test.shape[0]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 315
    },
    "id": "aa29tK9R8301",
    "outputId": "215d0d63-cb1f-43b4-a299-ab9d1188612a"
   },
   "outputs": [],
   "source": [
    "cm = metrics.plot_confusion_matrix(dt, X_test, y_test, xticks_rotation=\"vertical\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HhDxuLB49NQH",
    "outputId": "636351a0-e2ab-47cc-8ec6-59f7eb4c3ff2"
   },
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "  sample = X_test[i:i+1]\n",
    "  idx = np.argmax(dt.predict_proba(sample))\n",
    "  instru = STR_INT_MAP[idx]\n",
    "  print(\"Predicted: %s, Real: %s\" % (instru, y_test[i]))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "notebook.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
